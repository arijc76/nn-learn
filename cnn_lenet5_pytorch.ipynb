{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_lenet5_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arijc76/nn-learn/blob/master/cnn_lenet5_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCw6951SsYvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import show\n",
        "from bokeh.models import LinearAxis, Range1d\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxSU6Crsnw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 6\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjChMqr0soyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transforms to apply to the data\n",
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Wtq0Gkss8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files', train=True, download=True,\n",
        "                              transform=trans), batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files', train=False, download=True,\n",
        "                              transform=trans), batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qna1TdfWswFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(5 * 5 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7hh3Ic-G8bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGX_JSuvMRSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "cbb6f516-64c5-422d-8781-c8a5385eb36f"
      },
      "source": [
        "# Debugging\n",
        "\n",
        "#from torchvision import models\n",
        "#model = models.vgg16()\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (drop_out): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyNM6cjhG_wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L_6WYWyHDDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "0ec5af96-af5b-4e1d-dcbc-65443406847c"
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Run the forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Backprop and perform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/6], Step [100/600], Loss: 0.2960, Accuracy: 93.00%\n",
            "Epoch [1/6], Step [200/600], Loss: 0.1230, Accuracy: 95.00%\n",
            "Epoch [1/6], Step [300/600], Loss: 0.1356, Accuracy: 94.00%\n",
            "Epoch [1/6], Step [400/600], Loss: 0.1309, Accuracy: 96.00%\n",
            "Epoch [1/6], Step [500/600], Loss: 0.1446, Accuracy: 94.00%\n",
            "Epoch [1/6], Step [600/600], Loss: 0.1978, Accuracy: 94.00%\n",
            "Epoch [2/6], Step [100/600], Loss: 0.3903, Accuracy: 94.00%\n",
            "Epoch [2/6], Step [200/600], Loss: 0.0571, Accuracy: 99.00%\n",
            "Epoch [2/6], Step [300/600], Loss: 0.0979, Accuracy: 97.00%\n",
            "Epoch [2/6], Step [400/600], Loss: 0.1698, Accuracy: 94.00%\n",
            "Epoch [2/6], Step [500/600], Loss: 0.1991, Accuracy: 95.00%\n",
            "Epoch [2/6], Step [600/600], Loss: 0.2861, Accuracy: 93.00%\n",
            "Epoch [3/6], Step [100/600], Loss: 0.1269, Accuracy: 97.00%\n",
            "Epoch [3/6], Step [200/600], Loss: 0.0349, Accuracy: 100.00%\n",
            "Epoch [3/6], Step [300/600], Loss: 0.2512, Accuracy: 95.00%\n",
            "Epoch [3/6], Step [400/600], Loss: 0.1793, Accuracy: 96.00%\n",
            "Epoch [3/6], Step [500/600], Loss: 0.0894, Accuracy: 95.00%\n",
            "Epoch [3/6], Step [600/600], Loss: 0.0609, Accuracy: 98.00%\n",
            "Epoch [4/6], Step [100/600], Loss: 0.0271, Accuracy: 98.00%\n",
            "Epoch [4/6], Step [200/600], Loss: 0.0274, Accuracy: 99.00%\n",
            "Epoch [4/6], Step [300/600], Loss: 0.0938, Accuracy: 97.00%\n",
            "Epoch [4/6], Step [400/600], Loss: 0.0684, Accuracy: 99.00%\n",
            "Epoch [4/6], Step [500/600], Loss: 0.0689, Accuracy: 97.00%\n",
            "Epoch [4/6], Step [600/600], Loss: 0.1018, Accuracy: 98.00%\n",
            "Epoch [5/6], Step [100/600], Loss: 0.1155, Accuracy: 95.00%\n",
            "Epoch [5/6], Step [200/600], Loss: 0.0525, Accuracy: 99.00%\n",
            "Epoch [5/6], Step [300/600], Loss: 0.0543, Accuracy: 97.00%\n",
            "Epoch [5/6], Step [400/600], Loss: 0.0727, Accuracy: 98.00%\n",
            "Epoch [5/6], Step [500/600], Loss: 0.2770, Accuracy: 94.00%\n",
            "Epoch [5/6], Step [600/600], Loss: 0.1158, Accuracy: 95.00%\n",
            "Epoch [6/6], Step [100/600], Loss: 0.0578, Accuracy: 98.00%\n",
            "Epoch [6/6], Step [200/600], Loss: 0.0543, Accuracy: 98.00%\n",
            "Epoch [6/6], Step [300/600], Loss: 0.0372, Accuracy: 99.00%\n",
            "Epoch [6/6], Step [400/600], Loss: 0.1554, Accuracy: 95.00%\n",
            "Epoch [6/6], Step [500/600], Loss: 0.0703, Accuracy: 98.00%\n",
            "Epoch [6/6], Step [600/600], Loss: 0.0753, Accuracy: 97.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIlr2CTMHHBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1aa617b3-bfbd-42b9-c6e5-fae9a622446c"
      },
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 98.98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slUYx4GTO6B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}